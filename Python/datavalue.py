# -*- coding: utf-8 -*-
"""DataValue.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZPEHxr7C-PnWqUF5cOPXtQIM8udrw6Qy
"""



"""# New Section"""

import pickle
import requests
import re
from bs4 import BeautifulSoup
regex = (r"\d{5}\s{1}[a-zA-ZüÜöÖäÄ]+")
#url = "http://www.hgdf.de/"
#response = requests.get(url)
# parse html
#page = str(BeautifulSoup(response.content))

def readCsv():
  data = pd.read_csv("C:/Users/mfb0100/Nextcloud/DeeptechAI/data/urls.csv", sep = ";", encoding = "ISO-8859-1")
  return data

def getListOfURLs(csvData):
  urlList = list()
  for url in csvData.Domain:
    urlList.append(url)
  return urlList

def getURL(page):
    """

    :param page: html of web page (here: Python home page) 
    :return: urls in that page 
    """
    start_link = page.find("a href")
    if start_link == -1:
        return None, 0
    start_quote = page.find('"', start_link)
    end_quote = page.find('"', start_quote + 1)
    url = page[start_quote + 1: end_quote]
    return url, end_quote

def getImp(page):
  while True:
      url, n = getURL(page)
      page = page[n:]
      if url:
        if 'imp' in url:
          #print(url)
          return (url)          
      else:
          break

def buildImpURL(url):
  ImpLink =  getImp(page)
  #print(url)
  #print(ImpLink)
  if url and "www" not in ImpLink:
    #print("0")
    return url + '/' + getImp(page)
  else:
    #print("1")
    return ImpLink

#def getImpressionList():
  
  URLlist = getListOfURLs(readCsv())
  ImpDic = dict#list()
  for val in URLlist:
    
          url = ('https://' + val)
          #print(url)
          try:
            response = requests.get(url, timeout = 2)
          except Exception:
            response = ""
            pass
          try:
            page = str(BeautifulSoup(response.content))
            #print(page)
            adress = re.search(regex, page)
          except Exception:
            page = ""
            pass
          #print(page)
          try:
            a = buildImpURL(url)
            print(url)
            print(adress.group())
            ImpDic[url] = adress.group()#ImpDic.append(a)
           

            f = open("file.pkl","wb")
            pickle.dump(ImpDic,f)
            f.close()
           
          except Exception:
            pass
  #return ImpDic

"""# New Section"""

#Data List
import pandas as pd 

data = pd.read_csv("C:/Users/mfb0100/Nextcloud/DeeptechAI/data/urls.csv", sep = ";", encoding = "ISO-8859-1") 

#data.dtypes
#data.info()
data.head(100)
#print(data)
#list(data)

#Count Sections
import pandas as pd 

data = pd.read_csv("C:/Users/mfb0100/Nextcloud/DeeptechAI/data/urls.csv", sep = ";", encoding = "ISO-8859-1") 


#print(data)
#list(data)
sectionCount = data['WZ2008 Section'].value_counts()
sectionCount.head(30)

#Count Histogramm
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import StrMethodFormatter
data = pd.read_csv("C:/Users/mfb0100/Nextcloud/DeeptechAI/data/urls.csv", sep = ";", encoding = "ISO-8859-1") 

x = data['WZ2008 Section'].value_counts()


#sectionCount.head()
#hist = sectionCount.hist(bins = 30)
x.plot(kind='barh', figsize=(8, 10), color='#86bf91', zorder=2, width=0.85)