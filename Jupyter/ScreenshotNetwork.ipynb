{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ScreenshotNetwork.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "3MC6xr-XwvHM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "seed = 8\n",
        "np.random.seed(seed)\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import math\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from random import shuffle\n",
        "import scipy\n",
        "import cv2\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.keras import metrics \n",
        "\n",
        "def get_available_devices():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos]\n",
        "\n",
        "get_available_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "21ZfQIQ1yXuw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loadScreenshots():\n",
        "  screenDict = dict()\n",
        "  for root, dirs, files in os.walk(\"C:\\\\Users\\\\Adjek\\\\Nextcloud\\\\DeeptechAI\\\\picturesCut\"):\n",
        "    for file in files:\n",
        "      url = os.path.basename(os.path.normpath(root))\n",
        "      imgPath = os.path.join(root, file)\n",
        "      \n",
        "      if(file == \"convertedImg.jpg\"):\n",
        "        img = cv2.imread(imgPath, 0)\n",
        "        screenDict[url] = img\n",
        "      \n",
        "  return screenDict\n",
        "\n",
        "def createDataSet(enc, screens, csv):\n",
        "    \n",
        "    X = list()\n",
        "    Y = list()\n",
        "    U = list()\n",
        "    \n",
        "    for url in screens.keys():\n",
        "      #if(isinstance(csv[url], str) & (len(screens[url]) == 20)):\n",
        "        print(screens[url].shape)\n",
        "        X.append(screens[url])\n",
        "        Y.append(csv[url])\n",
        "        U.append(url)\n",
        "        \n",
        "    Y = enc.fit_transform(Y)\n",
        "    \n",
        "    return np.array(X), np.array(Y), U\n",
        "\n",
        "def reorderData(csv):\n",
        "    urlList = csv[\"Domain\"]\n",
        "    sectionList = csv[\"WZ2008 Section\"]\n",
        "    \n",
        "    resultDict = dict()\n",
        "    for i in range(len(urlList)):\n",
        "      resultDict[urlList[i]] = sectionList[i]\n",
        "      \n",
        "    return resultDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5rd7FBz3yaEi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"C:\\\\Users\\\\Adjek\\\\Nextcloud\\\\DeeptechAI\\\\data\\\\urls.csv\", sep = \";\", encoding = \"ISO-8859-1\")\n",
        "keyValueData = reorderData(data)\n",
        "\n",
        "screenshots = loadScreenshots()\n",
        "\n",
        "encoder = LabelBinarizer()\n",
        "dataSet_X, dataSet_Y, urls = createDataSet(encoder, screenshots, keyValueData)\n",
        "num_classes = dataSet_Y[1].shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXH1mYNY9_-m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(screenshots['www.auto-senger.de'].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JZn4qCEKB1Zg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataSet_X = dataSet_X.reshape(dataSet_X.shape[0], 84, 48, 1)\n",
        "print(dataSet_X.shape)\n",
        "#dataSet_Y = dataSet_Y.reshape(dataSet_Y.shape[0], 19, 1)\n",
        "#print(dataSet_Y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4EY3v6GB4y9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(dataSet_X.shape)\n",
        "print(dataSet_Y.shape)\n",
        "print(dataSet_Y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nOyFkoP1BVya",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainSize = math.floor(len(dataSet_X) * 0.6)\n",
        "validationSize = math.floor(len(dataSet_X) * 0.8)\n",
        "\n",
        "#shuffle(dataSet_X)\n",
        "#shuffle(dataSet_Y)\n",
        "\n",
        "\n",
        "train_X = dataSet_X[0:trainSize]\n",
        "train_Y = dataSet_Y[0:trainSize]\n",
        "train_U = urls[0:trainSize]\n",
        "\n",
        "validation_X = dataSet_X[trainSize:validationSize]\n",
        "validation_Y = dataSet_Y[trainSize:validationSize]\n",
        "validation_U = urls[trainSize:validationSize]\n",
        "\n",
        "test_X = dataSet_X[validationSize:len(dataSet_X)]\n",
        "test_Y = dataSet_Y[validationSize:len(dataSet_X)]\n",
        "test_U = urls[validationSize:len(dataSet_X)]\n",
        "\n",
        "print(len(train_X))\n",
        "print(len(validation_X))\n",
        "print(len(test_X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SxoSN9AYxOOi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def screenshot_model():\n",
        "    # create model\n",
        "    inputs = tf.keras.Input(shape=(84, 48, 1))\n",
        "    conv_1 = tf.keras.layers.Conv2D(10, (5, 5), activation=tf.nn.relu)(inputs)\n",
        "    max_1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv_1)\n",
        "    conv_2 = tf.keras.layers.Conv2D(5, (3, 3), activation=tf.nn.relu)(max_1)\n",
        "    max_2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv_2)\n",
        "    conv_3 = tf.keras.layers.Conv2D(5, (3, 3), activation=tf.nn.relu)(max_2)\n",
        "    max_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv_3)\n",
        "    drop_1 = tf.keras.layers.Dropout(0.5)(max_3)\n",
        "    flat_1 = tf.keras.layers.Flatten()(drop_1)\n",
        "    dense_1 = tf.keras.layers.Dense(5, activation=tf.nn.relu)(flat_1)\n",
        "    dense_2 = tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)(dense_1)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=inputs, outputs=dense_2)\n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[metrics.categorical_accuracy])\n",
        "    model.summary()\n",
        "    return model\n",
        "  \n",
        "def screenshot_small_model():\n",
        "    # create model\n",
        "    inputs = tf.keras.Input(shape=(84, 48, 1))\n",
        "    conv_1 = tf.keras.layers.Conv2D(10, (2, 2), activation=tf.nn.relu)(inputs)\n",
        "    max_1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv_1)\n",
        "    conv_2 = tf.keras.layers.Conv2D(10, (2, 2), activation=tf.nn.relu)(max_1)\n",
        "    max_2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv_2)\n",
        "    conv_3 = tf.keras.layers.Conv2D(10, (2, 2), activation=tf.nn.relu)(max_2)\n",
        "    max_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv_3)\n",
        "    conv_4 = tf.keras.layers.Conv2D(10, (2, 2), activation=tf.nn.relu)(max_3)\n",
        "    max_4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv_4)\n",
        "    conv_5 = tf.keras.layers.Conv2D(10, (2, 2), activation=tf.nn.relu)(max_4)\n",
        "    max_5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv_5)\n",
        "    drop_1 = tf.keras.layers.Dropout(0.5)(max_5)\n",
        "    flat_1 = tf.keras.layers.Flatten()(drop_1)\n",
        "    dense_1 = tf.keras.layers.Dense(5, activation=tf.nn.relu)(flat_1)\n",
        "    dense_2 = tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax)(dense_1)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=inputs, outputs=dense_2)\n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[metrics.categorical_accuracy])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fk9gXQHXxoJO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = 'C:\\\\Jupyter'\n",
        "tbCallBack = tf.keras.callbacks.TensorBoard(log_dir=path,\n",
        "                                            write_graph=True,\n",
        "                                            write_images=True,\n",
        "                                            histogram_freq=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LHej6-ivxqJT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title WÃ¤hle das Device\n",
        "\n",
        "# build the model\n",
        "device = '/device:CPU:0' #@param ['/device:CPU:0', '/device:GPU:0']\n",
        "with tf.device(device):\n",
        "    model = screenshot_model()\n",
        "    \n",
        "# Fit the model\n",
        "    model.fit(train_X, train_Y, validation_data=(validation_X, validation_Y), epochs=30, batch_size=200)\n",
        "\n",
        "# Final evaluation of the model\n",
        "    scores = model.evaluate(test_X, test_Y, verbose=1)\n",
        "print(\"Screenshot Network Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SXvsKZsgRRZA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "example_X = test_X[2:30]\n",
        "example_Y = test_Y[2:30]\n",
        "example_U = test_U[2:30]\n",
        "\n",
        "\n",
        "\n",
        "prediction = model.predict(example_X)\n",
        "\n",
        "predictedClasses = encoder.inverse_transform(prediction)\n",
        "originalClasses = encoder.inverse_transform(example_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wNb6DvyYpARf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print(prediction)\n",
        "\n",
        "for i in range(len(prediction)):\n",
        "  print(str(prediction[i].argmax()) + \"<->\" + str(example_Y[i].argmax()) + \" fÃ¼r URL: \" + example_U[i] + \" mit predicted Klasse \" + predictedClasses[i] + \" LÃ¶sung: \" + originalClasses[i])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}