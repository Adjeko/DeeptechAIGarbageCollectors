{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Website_Screenshot_Generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "_e6N-WtnIVuw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "import pandas as pd \n",
        "import urllib.request\n",
        "import os\n",
        " \n",
        "  \n",
        "def readCsv():\n",
        "  data = pd.read_csv(\"C:/Users/Philipp.Meier/Nextcloud/DeeptechAI/data/urls.csv\", sep = \";\", encoding = \"ISO-8859-1\")\n",
        "  return data\n",
        "\n",
        "def getListOfURLs(csvData):\n",
        "  urlList = list()\n",
        "  for url in csvData.Domain:\n",
        "    urlList.append(url)\n",
        "  return urlList\n",
        "\n",
        "def capture():\n",
        "\n",
        "    options = Options()\n",
        "    options.add_argument('-headless')\n",
        "    driver = webdriver.Firefox(executable_path = 'C:\\\\Users\\\\Philipp.Meier\\\\Nextcloud\\\\geckodriver.exe', options=options)\n",
        "\n",
        "    urlList = getListOfURLs(readCsv())\n",
        "    for i in range(0, len(urlList)):\n",
        "      url = urlList[i]\n",
        "      print(\"TRYING: \" + str(i))\n",
        "      try:\n",
        "        driver.get('https://' + url)\n",
        "      except urllib.error.URLError as e:\n",
        "        print(\"# URLError: Switching to http\")\n",
        "        try: \n",
        "          driver.get('http://' + url)\n",
        "        except Exception as e:\n",
        "          print(\"HTTP and HTTPS call not possible, skipping website...\" + url + str(e))\n",
        "          continue\n",
        "      except Exception as e:\n",
        "        print(\"Unhandled Error, skipping website...\" + url + str(e))\n",
        "        continue\n",
        "\n",
        "      \n",
        "      driver.maximize_window()   \n",
        "      scheight = 0\n",
        "      i=0\n",
        "      while scheight <= 1:\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight*%s);\" % scheight)\n",
        "        scheight += .33\n",
        "        print(\"Schreibe URL: \" + url + \" Nummer: \" + str(i))\n",
        "        directory = 'C:\\\\Users\\\\Philipp.Meier\\\\Nextcloud\\\\Websites\\\\%s' %(url)\n",
        "        if not os.path.exists(directory):\n",
        "          os.makedirs(directory)\n",
        "        driver.save_screenshot('C:\\\\Users\\\\Philipp.Meier\\\\Nextcloud\\\\Websites\\\\%s\\\\bild%d.png' %(url,i))\n",
        "        i+=1\n",
        "        \n",
        "    driver.quit()\n",
        "          \n",
        "      \n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KAnFgLn9FsCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "capture()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0wUdaIzaQBC8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "import pandas as pd \n",
        "import urllib.request\n",
        "import os\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        " \n",
        "  \n",
        "def readCsv():\n",
        "  data = pd.read_csv(\"C:/Users/Philipp.Meier/Nextcloud/DeeptechAI/data/urls.csv\", sep = \";\", encoding = \"ISO-8859-1\")\n",
        "  return data\n",
        "\n",
        "def getListOfURLs(csvData):\n",
        "  urlList = list()\n",
        "  for url in csvData.Domain:\n",
        "    urlList.append(url)\n",
        "  return urlList\n",
        "\n",
        "def capture2():\n",
        "\n",
        "    #options = Options()\n",
        "    #options.add_argument('-headless')\n",
        "    driver = webdriver.Firefox(executable_path = 'C:\\\\Users\\\\Philipp.Meier\\\\Nextcloud\\\\geckodriver.exe')\n",
        "    driver.maximize_window()\n",
        "    \n",
        "    verbose = 0\n",
        "\n",
        "    urlList = getListOfURLs(readCsv())\n",
        "    for i in range(3634, len(urlList)): \n",
        "      url = urlList[i]\n",
        "      print(\"TRYING \" + str(i))\n",
        "      try:\n",
        "        driver.get('https://' + url)\n",
        "      except urllib.error.URLError as e:\n",
        "        print(\"# URLError: Switching to http\")\n",
        "        try: \n",
        "          driver.get('http://' + url)\n",
        "        except Exception as e:\n",
        "          print(\"HTTP and HTTPS call not possible, skipping website...\" + url + str(e))\n",
        "          continue\n",
        "      except Exception as e:\n",
        "        print(\"Unhandled Error, skipping website...\" + url + str(e))\n",
        "        continue\n",
        "\n",
        "      \n",
        "      js = 'return Math.max( document.body.scrollHeight, document.body.offsetHeight,  document.documentElement.clientHeight,  document.documentElement.scrollHeight,  document.documentElement.offsetHeight);'\n",
        "\n",
        "      scrollheight = driver.execute_script(js)\n",
        "      if verbose > 0:\n",
        "          print(scrollheight)\n",
        "\n",
        "      slices = []\n",
        "      offset = 0\n",
        "      offset_arr=[]\n",
        "\n",
        "      while offset < scrollheight:\n",
        "          if verbose > 0: \n",
        "              print(offset)\n",
        "\n",
        "          #scroll page\n",
        "          if (scrollheight-offset)<offset:\n",
        "              driver.execute_script(\"window.scrollTo(0, %s);\" % (scrollheight-offset))\n",
        "              offset_arr.append(scrollheight-offset)\n",
        "          else:\n",
        "              driver.execute_script(\"window.scrollTo(0, %s);\" % offset)\n",
        "              offset_arr.append(offset)\n",
        "\n",
        "          try:  \n",
        "            img = Image.open(BytesIO(driver.get_screenshot_as_png()))\n",
        "          except Exception as e:\n",
        "            continue\n",
        "\n",
        "          offset += img.size[1]\n",
        "     \n",
        "          slices.append(img)\n",
        "\n",
        "          if verbose > 0:\n",
        "              driver.get_screenshot_as_file('screen_%s.jpg' % (offset))\n",
        "              print(scrollheight)\n",
        "\n",
        "      #take screenshot\n",
        "      screenshot = Image.new('RGB', (slices[0].size[0], scrollheight))\n",
        "      offset = 0\n",
        "      offset2= 0\n",
        "      for img in slices:\n",
        "          screenshot.paste(img, (0, offset_arr[offset2])) \n",
        "          offset += img.size[1]\n",
        "          offset2+= 1      \n",
        "\n",
        "      directory = 'C:\\\\Users\\\\Philipp.Meier\\\\Nextcloud\\\\Websites\\\\%s' % url\n",
        "      if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "      screenshot.save('C:\\\\Users\\\\Philipp.Meier\\\\Nextcloud\\\\Websites\\\\%s\\\\ganzeBild.png' % url)\n",
        "        \n",
        "    driver.quit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rnO_OIlfQCBa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "capture2()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}