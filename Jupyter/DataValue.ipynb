{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataValue.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PBbhPfDLJZvY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXrcNiCMCh4O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "mtkF0d57Hrcc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "regex = (r\"\\d{5}\\s{1}[a-zA-ZüÜöÖäÄ]+\")\n",
        "#url = \"http://www.hgdf.de/\"\n",
        "#response = requests.get(url)\n",
        "# parse html\n",
        "#page = str(BeautifulSoup(response.content))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "18tz-SOG8kKR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def readCsv():\n",
        "  data = pd.read_csv(\"C:/Users/mfb0100/Nextcloud/DeeptechAI/data/urls.csv\", sep = \";\", encoding = \"ISO-8859-1\")\n",
        "  return data\n",
        "\n",
        "def getListOfURLs(csvData):\n",
        "  urlList = list()\n",
        "  for url in csvData.Domain:\n",
        "    urlList.append(url)\n",
        "  return urlList\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_PiEQukju_xA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def getURL(page):\n",
        "    \"\"\"\n",
        "\n",
        "    :param page: html of web page (here: Python home page) \n",
        "    :return: urls in that page \n",
        "    \"\"\"\n",
        "    start_link = page.find(\"a href\")\n",
        "    if start_link == -1:\n",
        "        return None, 0\n",
        "    start_quote = page.find('\"', start_link)\n",
        "    end_quote = page.find('\"', start_quote + 1)\n",
        "    url = page[start_quote + 1: end_quote]\n",
        "    return url, end_quote\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ht_xpKRLGNUo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getImp(page):\n",
        "  while True:\n",
        "      url, n = getURL(page)\n",
        "      page = page[n:]\n",
        "      if url:\n",
        "        if 'imp' in url:\n",
        "          #print(url)\n",
        "          return (url)          \n",
        "      else:\n",
        "          break\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZAYw3bKMJ-pl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildImpURL(url):\n",
        "  ImpLink =  getImp(page)\n",
        "  #print(url)\n",
        "  #print(ImpLink)\n",
        "  if url and \"www\" not in ImpLink:\n",
        "    #print(\"0\")\n",
        "    return url + '/' + getImp(page)\n",
        "  else:\n",
        "    #print(\"1\")\n",
        "    return ImpLink"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hbgo-IUiR16E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#def getImpressionList():\n",
        "  \n",
        "  URLlist = getListOfURLs(readCsv())\n",
        "  ImpDic = dict#list()\n",
        "  for val in URLlist:\n",
        "    \n",
        "          url = ('https://' + val)\n",
        "          #print(url)\n",
        "          try:\n",
        "            response = requests.get(url, timeout = 2)\n",
        "          except Exception:\n",
        "            response = \"\"\n",
        "            pass\n",
        "          try:\n",
        "            page = str(BeautifulSoup(response.content))\n",
        "            #print(page)\n",
        "            adress = re.search(regex, page)\n",
        "          except Exception:\n",
        "            page = \"\"\n",
        "            pass\n",
        "          #print(page)\n",
        "          try:\n",
        "            a = buildImpURL(url)\n",
        "            print(url)\n",
        "            print(adress.group())\n",
        "            ImpDic[url] = adress.group()#ImpDic.append(a)\n",
        "           \n",
        "\n",
        "            f = open(\"file.pkl\",\"wb\")\n",
        "            pickle.dump(ImpDic,f)\n",
        "            f.close()\n",
        "           \n",
        "          except Exception:\n",
        "            pass\n",
        "  #return ImpDic\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-5hHHpUAaISF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "OEAJUjzu5Z7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Data List\n",
        "import pandas as pd \n",
        "\n",
        "data = pd.read_csv(\"C:/Users/mfb0100/Nextcloud/DeeptechAI/data/urls.csv\", sep = \";\", encoding = \"ISO-8859-1\") \n",
        "\n",
        "#data.dtypes\n",
        "#data.info()\n",
        "data.head(100)\n",
        "#print(data)\n",
        "#list(data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CHoUmFpGAAYi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Count Sections\n",
        "import pandas as pd \n",
        "\n",
        "data = pd.read_csv(\"C:/Users/mfb0100/Nextcloud/DeeptechAI/data/urls.csv\", sep = \";\", encoding = \"ISO-8859-1\") \n",
        "\n",
        "\n",
        "#print(data)\n",
        "#list(data)\n",
        "sectionCount = data['WZ2008 Section'].value_counts()\n",
        "sectionCount.head(30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EUAwRXXbJ5Fb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Count Histogramm\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import StrMethodFormatter\n",
        "data = pd.read_csv(\"C:/Users/mfb0100/Nextcloud/DeeptechAI/data/urls.csv\", sep = \";\", encoding = \"ISO-8859-1\") \n",
        "\n",
        "x = data['WZ2008 Section'].value_counts()\n",
        "\n",
        "\n",
        "#sectionCount.head()\n",
        "#hist = sectionCount.hist(bins = 30)\n",
        "x.plot(kind='barh', figsize=(8, 10), color='#86bf91', zorder=2, width=0.85)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bLvtyz9VaDze",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}