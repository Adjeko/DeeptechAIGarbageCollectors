{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "VpFkNxD-C1qq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading imports\n",
        "import logging\n",
        "import gensim\n",
        "import pickle\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "omAQ-OhmDbj7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loadData():\n",
        "  with open('C:\\\\Users\\\\Eduard\\\\Nextcloud\\\\DeeptechAI\\\\findingnouns\\\\taggedwords.pickle', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "    return data\n",
        "  \n",
        "data = loadData()\n",
        "print(data)\n",
        "# create data for model\n",
        "#file = \"\"\n",
        "#dictonary = pickle.load(open(file))\n",
        "\n",
        "document = []\n",
        "\n",
        "for key,value in data.items():\n",
        " document.append(value)\n",
        "\n",
        "\n",
        "logging.info (\"Done reading data file\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JTIKhsj0Eq9V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = gensim.models.Word2Vec (document, size=4, window=1, min_count=1, workers=2)\n",
        "model.train(document,total_examples=len(document),epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cB30W2mt2bSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#save\n",
        "save = {}\n",
        "\n",
        "for key,value in data.items():\n",
        "  v = []\n",
        "  for k in value:\n",
        "    v.append(model.wv.get_vector(k))\n",
        "  flat_list = [item for sublist in v for item in sublist]\n",
        "  tmp = {key : flat_list}\n",
        "  save.update(tmp)\n",
        "\n",
        "print(save)\n",
        "pickle.dump(save, open(\"words2vec.pickle\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iz3QSy_JnUTB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test other models"
      ]
    },
    {
      "metadata": {
        "id": "nJLvKjjzVhVT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load Google's pre-trained Word2Vec model.\n",
        "google_model = \"C:\\\\Users\\\\Eduard\\\\Downloads\\\\GoogleNews-vectors-negative300.bin\"\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(google_model, binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuR01Ymum0Qz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#save\n",
        "save = {}\n",
        "\n",
        "for key,value in data.items():\n",
        "  v = []\n",
        "  for k in value:\n",
        "    v.append(model.wv.get_vector(k))\n",
        "  flat_list = [item for sublist in v for item in sublist]\n",
        "  tmp = {key : flat_list}\n",
        "  save.update(tmp)\n",
        "\n",
        "print(save)\n",
        "pickle.dump(save, open(\"words2vec_google.pickle\", \"wb\"))  # save it into a file named save.p"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}